{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Tagging Patterns\n",
    "### Tanya Balaraju\n",
    "#### Modified from Homework 2 in Class\n",
    "Matthew Stone, CS 533, to accompany second homework.\n",
    "Initial version, Spring 2017.  Updated Spring 2018.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "import vocabulary\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import heapq\n",
    "import tagtools\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_train_file, reference_test_file, reference_dev_file = \\\n",
    "  \"reference_train.xml\", \"reference_test.xml\", \"reference_dev.xml\"\n",
    "reference_xml_item_keyword = \"entry\"\n",
    "\n",
    "ingredients_train_file, ingredients_test_file, ingredients_dev_file = \\\n",
    "  \"ingredients_small_train.xml\", \"ingredients_small_test.xml\", \"ingredients_devset.xml\"\n",
    "#  \"ingredients_big_train.xml\", \"ingredients_big_test.xml\", \"ingredients_devset.xml\"\n",
    "ingredients_xml_item_keyword = \"ingredient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_contexts(seq) :\n",
    "    '''take the tagged tokens in seq and create a new sequence \n",
    "    that yields the same tokens but presents them with the full\n",
    "    context that precedes and follows them'''\n",
    "    items = [x for x in seq]\n",
    "    words = [w for (w,_) in items]\n",
    "    for i, (w, t) in enumerate(items) :\n",
    "        if i == 0 :\n",
    "            before = []\n",
    "        else :\n",
    "            before = words[i-1::-1]\n",
    "        after = words[i+1:]\n",
    "        yield (w, before, after), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cxt_feature_processor(word_tests, list_tests) :\n",
    "    def feature_processor(features, item) :\n",
    "        this, before, after = item\n",
    "        result = []\n",
    "        \n",
    "        def addf(name) :\n",
    "            if name :\n",
    "                r = features.add(name)\n",
    "                if r :\n",
    "                    result.append(r)\n",
    "\n",
    "        def add_word_features(w, code) :\n",
    "            for ff in word_tests :\n",
    "                addf(ff(w, code))\n",
    "\n",
    "        def add_list_features(l, code) :\n",
    "            for ff in list_tests :\n",
    "                addf(ff(l, code))\n",
    "\n",
    "        first = lambda l: l[0] if l else None\n",
    "        \n",
    "        add_word_features(this, u\"w\")\n",
    "        add_list_features(before, u\"-\")\n",
    "        add_list_features(after, u\"+\")\n",
    "        for wx, cx in [(first(before), u\"-w\"),\n",
    "                       (first(after), u\"+w\")] :\n",
    "            if wx :\n",
    "                add_word_features(wx, cx)\n",
    "    \n",
    "        return np.array(result)\n",
    "    return feature_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing specific feature detectors\n",
    "\n",
    "### Model Features\n",
    "\n",
    "Here are some model features to give a sense of what's involved in writing the pattern matching routines for a feature processor.\n",
    "\n",
    "* The `identity_feature` constructs a feature for the item itself.  It shows how you can incorporate material from the item into the feature definition you create on a match.  Token identity is always a good default for memorizing arbitrary associations in a classification problem.\n",
    "\n",
    "* The `all_digits` feature tests whether a word item consists entirely of numerical characters, e.g., matches `[0-9]*`  In the bibliography context, this might be a good starting cue to recognize a date or for the volume number of a journal.  In the recipe domain this might be a good cue for recognizing the quantity of an ingredient.\n",
    "\n",
    "* The `lonely_initial` feature tests whether something looks like an abbreviated first name, which of course is useful for identifying author and editor fields in bibliographies: a two character token consisting of an upper case letter and a period (e.g,. `A.`)\n",
    "\n",
    "* The `is_empty` feature tests whether a list context contains no tokens.  When applied to the context features for a target token, this feature fires in one way when the target token is the first token in a text sequence and in another way when the target token is the final token in a text sequence.  This makes it generally useful for identifying material that's consistently placed at the beginning or end of descriptions (e.g., author vs date in bibliography entries, or quantity vs comment in recipe elements).\n",
    "\n",
    "#### New features added:\n",
    "\n",
    "* The `is_web_addr` function identifies one of two features: `is_email` and `is_website`, based on the formatting of the `item` passed in. It was useful to include both features in the same function due to the similarity of their formatting.\n",
    "\n",
    "* The `is_quantity` feature determines whether an item is a fraction--useful for identifying quantities (particularly fractions) in recipes.\n",
    "\n",
    "* The `is_page_range` feature determines whether an item is a page range, most often denoted by the formatting `<number>-<number>` but also inclusive of other possible formats.\n",
    "\n",
    "* The `is_year` feature checks whether an item is a four-digit number likely to be a year.\n",
    "\n",
    "* The `is_institution` feature checks for institution-related words that determine whether the item in question is a university.\n",
    "\n",
    "* The `is_volume` feature denotes whether an item is a volume, which is usually formatted as `<number>(<number>)`.\n",
    "\n",
    "* The `is_author` feature uses detection of single initials to determine whether a name belongs to an author. This is a list-based feature, because author names are split up.\n",
    "\n",
    "* The `is_location` feature uses both Wordnet and a Part of Speech Tagger to determine whether an item is likely to be a location. In particular, it looks for whether the Wordnet definition of an item contains the word \"city\" and whether the POS Tagger tags the item as a proper noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_feature = lambda item, code: \"{}: {}\".format(code, item)\n",
    "\n",
    "def all_digits(item, code) :\n",
    "    if item.isdigit() :\n",
    "        return u\"{}: is all digits\".format(code)\n",
    "    \n",
    "def lonely_initial(item, code) :\n",
    "    if len(item) == 2 and item[0].isupper and item[1] == '.' :\n",
    "        return u\"{}: lonely initial\".format(code)\n",
    "    \n",
    "def is_empty(l, code) :\n",
    "    if not l :\n",
    "        return u\"{}: empty\".format(code)\n",
    "\n",
    "def is_web_addr(l, code):\n",
    "    domains = {'.com', '.org', '.net', '.edu', '.gov', '.cn', \\\n",
    "                      '.uk', '.eu', '.ru', '.info', '.nl', '.de'}\n",
    "    def is_email():\n",
    "        if '@' in l and True in [x in l[l.index('@'):] for x in domains]:\n",
    "            return True\n",
    "        return False\n",
    "    def is_website():\n",
    "        if True in ([i in l for i in domains]):\n",
    "            return True\n",
    "        return False\n",
    "    if is_email(): return u\"{}: is email\".format(code)\n",
    "    if is_website(): return u\"{}: is website\".format(code)\n",
    "    \n",
    "def is_quantity(item, code):\n",
    "    if item.replace('/', '').replace(' ', '').isdigit() and '/' in item:\n",
    "        return u\"{}: is quantity\".format(code)\n",
    "\n",
    "def is_page_range(item, code):\n",
    "    if item.replace('-', '').replace(',','').replace('.','').isdigit() and '-' in item:\n",
    "        return u\"{}: is page range\".format(code)\n",
    "\n",
    "def is_year(item, code):\n",
    "    if len(item.replace('-','').replace(',','')) == 4 and ('19' in item[:1] or '20' in item[:1]):\n",
    "        return u\"{}: is year\".format(code)\n",
    "\n",
    "def is_institution(item, code):\n",
    "    if 'University' in item or 'Univ' in item or 'Universite' in item or 'MIT' in item:\n",
    "        return u\"{}: is institution\".format(code)\n",
    "\n",
    "def is_author(l, code):\n",
    "    #print (l)\n",
    "    if len(l) > 0 and len(l[0]) == 2:\n",
    "        if l[0][1] == '.' and l[0].replace('.','').isupper():\n",
    "            return u\"{}: is author\".format(code)\n",
    "\n",
    "def is_volume(item, code):\n",
    "    new = item.replace('(', '').replace(')', '').replace(',','')\n",
    "    if len(new) <= 3 and new.isdigit():\n",
    "        return u\"{}: is volume\".format(code)\n",
    "\n",
    "def is_location(item, code):\n",
    "    syns = wordnet.synsets(item)\n",
    "    if len(syns) > 0:\n",
    "        if 'town' in syns[0].definition() or 'city' in syns[0].definition():\n",
    "            pos = pos_tag([item])\n",
    "            w, t = pos[0]\n",
    "            if t == 'NNP':\n",
    "                return u\"{}: is location\".format(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `feature_processor` call was updated to include the new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "default_tokenizer = \\\n",
    "    lambda i: tagged_contexts(tagtools.bies_tagged_tokens(i))\n",
    "default_token_view = lambda i : i[0]\n",
    "default_feature_processor = \\\n",
    "    make_cxt_feature_processor([all_digits, lonely_initial, \n",
    "                                identity_feature, is_quantity, \n",
    "                                is_page_range, is_year, is_institution, \n",
    "                                is_location, is_volume],\n",
    "                               [is_empty, is_web_addr, is_author])\n",
    "def default_features(vocab) :\n",
    "    return lambda data: vocab\n",
    "\n",
    "bib_features = vocabulary.Vocabulary()\n",
    "\n",
    "bib_data = tagtools.DataManager(reference_train_file, \n",
    "                                reference_test_file, \n",
    "                                reference_dev_file,\n",
    "                                reference_xml_item_keyword,\n",
    "                                default_tokenizer,\n",
    "                                default_token_view,\n",
    "                                default_features(bib_features),\n",
    "                                default_feature_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_data.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventura (b: author)\n",
      "\t-: empty\t+w: ,\n",
      ", (i: author)\n",
      "\tw: ,\t-w: Ventura\t+w: Dan\n",
      "Dan (i: author)\n",
      "\t+w: ,\tw: Dan\t-w: ,\n",
      ", (e: author)\n",
      "\tw: ,\t-w: Dan\t+w: (\n",
      "( (b: date)\n",
      "\t-w: ,\tw: (\t+w: is all digits\t+w: 1995\n",
      "1995 (i: date)\n",
      "\tw: is all digits\tw: 1995\t-w: (\t+w: )\n",
      ") (i: date)\n",
      "\tw: )\t-w: is all digits\t-w: 1995\t+w: .\n",
      ". (e: date)\n",
      "\tw: .\t-w: )\t+w: On\n",
      "On (b: title)\n",
      "\tw: On\t-w: .\t+w: Discretization\n",
      "Discretization (i: title)\n",
      "\tw: Discretization\t-w: On\t+w: as\n",
      "as (i: title)\n",
      "\tw: as\t-w: Discretization\t+w: a\n",
      "a (i: title)\n",
      "\tw: a\t-w: as\t+w: Preprocessing\n",
      "Preprocessing (i: title)\n",
      "\tw: Preprocessing\t-w: a\t+w: Step\n",
      "Step (i: title)\n",
      "\tw: Step\t-w: Preprocessing\t+w: for\n",
      "for (i: title)\n",
      "\tw: for\t-w: Step\t+w: Supervised\n",
      "Supervised (i: title)\n",
      "\tw: Supervised\t-w: for\t+w: Learning\n",
      "Learning (i: title)\n",
      "\tw: Learning\t-w: Supervised\t+w: Models\n",
      "Models (i: title)\n",
      "\t+w: ,\tw: Models\t-w: Learning\n",
      ", (e: title)\n",
      "\tw: ,\t-w: Models\t+w: Masters\n",
      "Masters (b: tech)\n",
      "\t-w: ,\tw: Masters\t+w: Thesis\n",
      "Thesis (i: tech)\n",
      "\t+w: ,\tw: Thesis\t-w: Masters\n",
      ", (e: tech)\n",
      "\tw: ,\t-w: Thesis\t+w: Department\n",
      "Department (b: institution)\n",
      "\t-w: ,\tw: Department\t+w: of\n",
      "of (i: institution)\n",
      "\tw: of\t-w: Department\t+w: Computer\n",
      "Computer (i: institution)\n",
      "\tw: Computer\t-w: of\t+w: Science\n",
      "Science (i: institution)\n",
      "\t+w: ,\tw: Science\t-w: Computer\n",
      ", (i: institution)\n",
      "\tw: ,\t-w: Science\t+w: Brigham\n",
      "Brigham (i: institution)\n",
      "\t-w: ,\tw: Brigham\t+w: Young\n",
      "Young (i: institution)\n",
      "\tw: Young\t-w: Brigham\t+w: University\t+w: is institution\n",
      "University (i: institution)\n",
      "\t+w: .\tw: University\tw: is institution\t-w: Young\n",
      ". (e: institution)\n",
      "\tw: .\t+: empty\t-w: University\t-w: is institution\n"
     ]
    }
   ],
   "source": [
    "bib_data.test_features_dev_item(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we can use exactly the same family of operations to describe the recipe data.  If you want to explore both recipe data and bibliography data yourself, however, you may want to consider using different features and maybe even different tagging pipelines for the two data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_features = vocabulary.Vocabulary()\n",
    "\n",
    "recipe_data = tagtools.DataManager(ingredients_train_file, \n",
    "                                   ingredients_test_file,\n",
    "                                   ingredients_dev_file,\n",
    "                                   ingredients_xml_item_keyword,\n",
    "                                   default_tokenizer,\n",
    "                                   default_token_view,\n",
    "                                   default_features(recipe_features),\n",
    "                                   default_feature_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have a separate cell to load the data from the file system.  (The recipe data is very large; this takes a while!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_data.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaggingExperiment was updated with the function `test()` to run the classifier and decoder on the test data. This function is almost exactly the same as `decode_and_validate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingExperiment(object) :\n",
    "    '''Organize the process of getting data, building a classifier,\n",
    "    and exploring new representations'''\n",
    "    \n",
    "    def __init__(self, data, features, classifier, decoder) :\n",
    "        'set up the problem of learning a classifier from a data manager'\n",
    "        self.data = data\n",
    "        self.classifier = classifier\n",
    "        self.features = features\n",
    "        self.decoder = decoder\n",
    "        self.initialized = False\n",
    "        self.trained = False\n",
    "        self.decoded = False\n",
    "        \n",
    "    def initialize(self) :\n",
    "        'materialize the training data, dev data and test data as matrices'\n",
    "        if not self.initialized :\n",
    "            self.train_X, self.train_y, self.train_d = self.data.training_data()\n",
    "            self.features.stop_growth()\n",
    "            self.dev_X, self.dev_y, self.dev_d = self.data.dev_data()\n",
    "            self.test_X, self.test_y, self.test_d = self.data.test_data()\n",
    "            self.initialized = True\n",
    "        \n",
    "    def fit_and_validate(self) :\n",
    "        'train the classifier and assess predictions on dev data'\n",
    "        if not self.initialized :\n",
    "            self.initialize()\n",
    "        self.classifier.fit(self.train_X, self.train_y)\n",
    "        self.tagset = self.classifier.classes_\n",
    "        self.trained = True\n",
    "        self.dev_predictions = self.classifier.predict(self.dev_X)\n",
    "        self.accuracy = sklearn.metrics.accuracy_score(self.dev_y, self.dev_predictions)\n",
    "    \n",
    "    def visualize_classifier(self, item_number) :\n",
    "        'show the results of running the classifier on text number item_number'\n",
    "        if not self.trained :\n",
    "            self.fit_and_validate()\n",
    "        w = self.data.dev_item_token_views(item_number)\n",
    "        s = self.dev_d[item_number]\n",
    "        e = self.dev_d[item_number+1]\n",
    "        tagtools.visualize(w, {'actual': self.dev_y[s:e], \n",
    "                               'predicted': self.dev_predictions[s:e]})\n",
    "\n",
    "    def decode_and_validate(self) :\n",
    "        '''use the trained classifier and beam search to find the consistent\n",
    "        analyses of all the items in the dev data'''\n",
    "        if not self.trained :\n",
    "            self.fit_and_validate()\n",
    "        self.dev_log_probs = self.classifier.predict_log_proba(self.dev_X)\n",
    "        results = []\n",
    "        self.dev_partials = []\n",
    "        self.dev_exacts = []\n",
    "        for i in range(len(self.dev_d)-1) :\n",
    "            s = self.dev_d[i]\n",
    "            e = self.dev_d[i+1]\n",
    "            tags, score = self.decoder.search(self.tagset, self.dev_log_probs[s:e])\n",
    "            p_t = tags[1:-1]\n",
    "            results.append(p_t)\n",
    "            self.dev_partials.append(tagtools.agrees(p_t, iter(self.dev_y[s:e]), partial=True))\n",
    "            self.dev_exacts.append(tagtools.agrees(p_t, iter(self.dev_y[s:e]), partial=False))\n",
    "        self.dev_decoded = np.concatenate(results)\n",
    "    \n",
    "    def test(self):\n",
    "        if not self.trained :\n",
    "            self.fit_and_validate()\n",
    "        self.test_predictions = self.classifier.predict(self.test_X)\n",
    "        self.test_accuracy = sklearn.metrics.accuracy_score(self.test_y, self.test_predictions)\n",
    "        self.test_log_probs = self.classifier.predict_log_proba(self.test_X)\n",
    "        results = []\n",
    "        self.test_partials = []\n",
    "        self.test_exacts = []\n",
    "        for i in range(len(self.test_d)-1) :\n",
    "            s = self.test_d[i]\n",
    "            e = self.test_d[i+1]\n",
    "            tags, score = self.decoder.search(self.tagset, self.test_log_probs[s:e])\n",
    "            p_t = tags[1:-1]\n",
    "            results.append(p_t)\n",
    "            self.test_partials.append(tagtools.agrees(p_t, iter(self.test_y[s:e]), partial=True))\n",
    "            self.test_exacts.append(tagtools.agrees(p_t, iter(self.test_y[s:e]), partial=False))\n",
    "        self.test_decoded = np.concatenate(results)\n",
    "        \n",
    "    def visualize_decoder(self, item) :\n",
    "        'show the results of running the classifier and decoder on text number item_number'\n",
    "        if not self.decoded :\n",
    "            self.decode_and_validate()\n",
    "        w = self.data.dev_item_token_views(item)\n",
    "        s = self.dev_d[item]\n",
    "        e = self.dev_d[item+1]\n",
    "        tagtools.visualize(w, {'actual': self.dev_y[s:e], \n",
    "                               'best': self.dev_predictions[s:e],\n",
    "                               'predicted': self.dev_decoded[s:e]})\n",
    "\n",
    "    @classmethod\n",
    "    def transform(cls, expt, operation, classifier) :\n",
    "        'use operation to transform the data from expt and set up new classifier'\n",
    "        if not expt.initialized :\n",
    "            expt.initialize()\n",
    "        result = cls(expt.data, classifier)\n",
    "        result.train_X, result.train_y, result.train_d = \\\n",
    "            operation(expt.train_X, expt.train_y, expt.train_d)\n",
    "        result.dev_X, result.dev_y, result.dev_d = \\\n",
    "            operation(expt.dev_X, expt.dev_y, expt.dev_d)\n",
    "        result.test_X, result.test_y, result.test_d = \\\n",
    "            operation(expt.test_X, expt.test_y, expt.test_d)\n",
    "        result.initialized = True\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Consistent Taggings\n",
    "\n",
    "The four functions below were modified as follows:\n",
    "\n",
    "* `initial_status()`: This remains unchanged.\n",
    "\n",
    "* `is_consistent(t1, t2)`: The basic rules for this function are listed in the comments within the function. In general, an 'i' or 'e' tag must follow a 'b' or 'i' tag, and an 's' or 'b' tag must follow an 'e' or 's' tag. In the former case, the tags (such as 'author') must match; in the latter case, they should not match. This makes sense--'b' or 'i' 'author' tags can logically be followed by another author, but an 'e' or 's' tag for 'author' means that there cannot be another author following it.\n",
    "\n",
    "* `next_status(status, t1, t2)`: The basic notion behind this function is that the tags journal, booktitle, tech, and quantity MUST be unique in a single entry. However, 'note', 'comment', and 'other' can appear multiple times.\n",
    "\n",
    "* `do_special(status, t1, j, node, heuristics)`.  `do_special` follows up on `next_status` by addressing the case in which the tags 'note', 'comment', or 'other' appear in an entry. When these are present, the other constraints are no longer enforced. This is also true when a supposedly \"unique\" tag appears more than once in an entry. Whereas the default heuristic is 100,000, this is changed when the \"rules\" are \"broken,\" and the value is modified to the heuristic value at index j.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good default\n",
    "def initial_status():\n",
    "    return frozenset(['START'])\n",
    "\n",
    "def is_consistent(t1, t2) :\n",
    "    #(i or e) must follow (b or i) and tags should match\n",
    "    #(s or b) must follow (e or s) and tags shouldn't match\n",
    "    if t2 == 'START' and t1 == 'END' : return False\n",
    "    return (t1 == 'START' and t2[0] == 'b') or \\\n",
    "        (t2 == 'END' and (t1[0] == 'e' or t1[0] == 's')) or \\\n",
    "        (((t1[0] == 'b' or t1[0] == 'i') and (t2[0] == 'i' or t2[0] == 'e')) and t1[3:] == t2[3:]) or \\\n",
    "        (((t1[0] == 'e' or t1[0] == 's') and (t2[0] == 's' or t2[0] == 'b')) and t1[3:] != t2[3:])\n",
    "\n",
    "def next_status(status, t1, t2) :\n",
    "    #first dataset: note can be multiple, \n",
    "        #have to be individual: journal, booktitle, tech\n",
    "    #second dataset: comments and other can be multiple, quantities cannot\n",
    "    unique = {'journal', 'booktitle', 'tech', 'quantity'}\n",
    "    not_unique = {'note', 'comment', 'other'}\n",
    "    single = {'author', 'date', 'title', 'volume', 'location', 'publisher', 'institution', 'editor', 'paper', 'date'}\n",
    "    field1 = t1[3:]\n",
    "    field2 = t2[3:]\n",
    "    if field2 in single and field2 not in status: return status.union([field2])\n",
    "    if field2 in not_unique: return status.union([field2])\n",
    "    if field2 in unique and len(status & not_unique) == 0: \n",
    "        return status.union([field2])\n",
    "    return status\n",
    "\n",
    "def do_special(status, t1, j, node, heuristics):\n",
    "    #model failure: if t1 is in the \"not_unique\" set from before\n",
    "    not_unique = {'note', 'comment', 'other'}\n",
    "    special_node = node    \n",
    "    new_value = 100000\n",
    "    for i in range(j, len(heuristics) - 2) :\n",
    "        special_node = (None, special_node)\n",
    "    if t1 not in {'START', 'END'} and t1[3:] in status and len(status & not_unique) != 0:\n",
    "        new_value = heuristics[j]\n",
    "    return [(special_node, new_value)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up experiments\n",
    "\n",
    "The definitions below put everything together.  We create a classifier to learn correlations between features and tags, and crate a decoder to put the learned decisions together into an analyses of complete texts.  Then we set up the infrastructure to explore the results systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_classifier = sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                           penalty=\"elasticnet\",\n",
    "                                           n_iter=5)\n",
    "\n",
    "\n",
    "bib_decoder = tagtools.BeamDecoder(initial_status,\n",
    "                                   is_consistent,\n",
    "                                   next_status,\n",
    "                                   do_special)\n",
    "\n",
    "bib = TaggingExperiment(bib_data, \n",
    "                        bib_features,\n",
    "                        bib_classifier,\n",
    "                        bib_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bib.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier and explore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanya/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "bib.fit_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8100526008182349\n"
     ]
    }
   ],
   "source": [
    "print (bib.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some errors.\n",
      "('Jeffrey        ', u'\\tactual     b: author \\tpredicted  b: author ')\n",
      "('Kuskin         ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('David          ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Ofelt          ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Mark           ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Heinrich       ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('John           ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Heinlein       ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Richard        ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Simoni         ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Kourosh        ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Gharachorloo   ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('John           ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Chapin         ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('David          ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Nakahira       ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Joel           ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Baxter         ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Mark           ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Horowitz       ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Anoop          ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Gupta          ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Mendel         ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('Rosenbaum      ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "(',              ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('and            ', u'\\tactual     i: author \\tpredicted  i: author ')\n",
      "('John           ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "('Hennessy       ', u'\\tactual     i: author \\tpredicted  i: title  ')\n",
      "('.              ', u'\\tactual     e: author \\tpredicted  e: author ')\n",
      "('The            ', u'\\tactual     b: title  \\tpredicted  b: title  ')\n",
      "('Stanford       ', u'\\tactual     i: title  \\tpredicted  i: title  ')\n",
      "('FLASH          ', u'\\tactual     i: title  \\tpredicted  i: title  ')\n",
      "('multiprocessor ', u'\\tactual     i: title  \\tpredicted  i: title  ')\n",
      "('.              ', u'\\tactual     e: title  \\tpredicted  e: title  ')\n",
      "('In             ', u'\\tactual     b: booktitle\\tpredicted  b: booktitle')\n",
      "('Proceedings    ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('of             ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('the            ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('21st           ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('Annual         ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('International  ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('Conference     ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('on             ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('Computer       ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "('Architecture   ', u'\\tactual     i: booktitle\\tpredicted  i: booktitle')\n",
      "(',              ', u'\\tactual     e: booktitle\\tpredicted  e: booktitle')\n",
      "('pages          ', u'\\tactual     b: pages  \\tpredicted  b: pages  ')\n",
      "('302-313        ', u'\\tactual     i: pages  \\tpredicted  i: pages  ')\n",
      "(',              ', u'\\tactual     e: pages  \\tpredicted  e: pages  ')\n",
      "('April          ', u'\\tactual     b: date   \\tpredicted  b: date   ')\n",
      "('1994           ', u'\\tactual     i: date   \\tpredicted  i: date   ')\n",
      "('.              ', u'\\tactual     e: date   \\tpredicted  e: date   ')\n"
     ]
    }
   ],
   "source": [
    "bib.visualize_classifier(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for consistent analyses and report details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 correct with omissions\n",
      "15 fully correct\n"
     ]
    }
   ],
   "source": [
    "bib.decode_and_validate()\n",
    "print (sum([1 for t in bib.dev_partials if t]), \"correct with omissions\")\n",
    "print (sum([1 for t in bib.dev_exacts if t]), \"fully correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     b: author       0.96      0.98      0.97        49\n",
      "     i: author       0.80      0.93      0.86       338\n",
      "     e: author       0.69      0.92      0.79        49\n",
      "  e: booktitle       0.68      0.52      0.59        25\n",
      "  i: booktitle       0.88      0.76      0.82       209\n",
      "  b: booktitle       0.85      0.88      0.86        25\n",
      "       i: date       0.81      1.00      0.89        50\n",
      "       e: date       0.78      0.96      0.86        49\n",
      "       b: date       0.91      0.98      0.94        49\n",
      "     b: editor       0.00      0.00      0.00         6\n",
      "     e: editor       0.00      0.00      0.00         6\n",
      "     i: editor       0.93      0.30      0.45        44\n",
      "i: institution       0.73      0.40      0.52        20\n",
      "b: institution       0.50      0.14      0.22         7\n",
      "e: institution       1.00      0.43      0.60         7\n",
      "    i: journal       0.58      0.29      0.39        38\n",
      "    b: journal       0.90      0.56      0.69        16\n",
      "    e: journal       0.63      0.75      0.69        16\n",
      "   i: location       0.85      0.39      0.54        28\n",
      "   b: location       0.86      0.46      0.60        13\n",
      "   e: location       0.54      0.54      0.54        13\n",
      "   s: location       0.00      0.00      0.00         1\n",
      "       e: note       0.00      0.00      0.00         4\n",
      "       i: note       0.00      0.00      0.00        11\n",
      "       b: note       0.00      0.00      0.00         4\n",
      "      i: pages       0.97      1.00      0.98        30\n",
      "      b: pages       1.00      0.94      0.97        33\n",
      "      e: pages       1.00      0.91      0.95        33\n",
      "  b: publisher       0.86      0.60      0.71        10\n",
      "  i: publisher       0.80      0.33      0.47        12\n",
      "  e: publisher       0.80      0.40      0.53        10\n",
      "       e: tech       1.00      0.20      0.33         5\n",
      "       b: tech       1.00      0.80      0.89         5\n",
      "       i: tech       1.00      0.50      0.67        10\n",
      "      b: title       0.73      0.96      0.83        50\n",
      "      e: title       0.93      0.76      0.84        50\n",
      "      i: title       0.78      0.94      0.85       335\n",
      "     i: volume       0.71      1.00      0.83        22\n",
      "     e: volume       0.62      0.62      0.62        13\n",
      "     b: volume       0.69      0.85      0.76        13\n",
      "     s: volume       1.00      1.00      1.00         3\n",
      "\n",
      "   avg / total       0.80      0.81      0.79      1711\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanya/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print (tagtools.bieso_classification_report(bib.dev_y, bib.dev_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize performance of the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     b: author       1.00      0.92      0.96        49\n",
      "     i: author       1.00      0.82      0.90       338\n",
      "     e: author       0.96      0.88      0.91        49\n",
      "  e: booktitle       0.75      0.36      0.49        25\n",
      "  i: booktitle       0.99      0.40      0.57       209\n",
      "  b: booktitle       0.92      0.44      0.59        25\n",
      "       i: date       0.90      0.72      0.80        50\n",
      "       e: date       0.93      0.51      0.66        49\n",
      "       b: date       0.93      0.51      0.66        49\n",
      "     b: editor       1.00      0.17      0.29         6\n",
      "     e: editor       1.00      0.17      0.29         6\n",
      "     i: editor       1.00      0.09      0.17        44\n",
      "i: institution       1.00      0.35      0.52        20\n",
      "b: institution       1.00      0.14      0.25         7\n",
      "e: institution       1.00      0.14      0.25         7\n",
      "    i: journal       1.00      0.18      0.31        38\n",
      "    b: journal       1.00      0.31      0.48        16\n",
      "    e: journal       1.00      0.31      0.48        16\n",
      "   i: location       1.00      0.11      0.19        28\n",
      "   b: location       1.00      0.08      0.14        13\n",
      "   e: location       1.00      0.08      0.14        13\n",
      "   s: location       0.00      0.00      0.00         1\n",
      "       e: note       0.00      0.00      0.00         4\n",
      "       i: note       0.00      0.00      0.00        11\n",
      "       b: note       0.00      0.00      0.00         4\n",
      "      i: pages       1.00      0.30      0.46        30\n",
      "      b: pages       1.00      0.39      0.57        33\n",
      "      e: pages       1.00      0.39      0.57        33\n",
      "  b: publisher       1.00      0.10      0.18        10\n",
      "  i: publisher       1.00      0.08      0.15        12\n",
      "  e: publisher       1.00      0.10      0.18        10\n",
      "       e: tech       1.00      0.20      0.33         5\n",
      "       b: tech       1.00      0.20      0.33         5\n",
      "       i: tech       1.00      0.10      0.18        10\n",
      "      b: title       1.00      0.54      0.70        50\n",
      "      e: title       0.93      0.50      0.65        50\n",
      "      i: title       0.97      0.60      0.74       335\n",
      "     i: volume       1.00      0.27      0.43        22\n",
      "     e: volume       1.00      0.31      0.47        13\n",
      "     b: volume       1.00      0.31      0.47        13\n",
      "     s: volume       1.00      0.33      0.50         3\n",
      "\n",
      "   avg / total       0.97      0.53      0.65      1711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (tagtools.bieso_classification_report(bib.dev_y, bib.dev_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibligraphy Test Data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Performance \n",
      " Accuracy: 0.830203916818\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     b: author       0.99      1.00      0.99       148\n",
      "     i: author       0.80      0.96      0.87       970\n",
      "     e: author       0.77      0.92      0.84       148\n",
      "  e: booktitle       0.74      0.48      0.59        66\n",
      "  i: booktitle       0.80      0.71      0.75       477\n",
      "  b: booktitle       0.84      0.85      0.84        66\n",
      "       i: date       0.92      0.94      0.93       171\n",
      "       e: date       0.87      0.97      0.91       147\n",
      "       b: date       0.94      0.95      0.95       147\n",
      "     b: editor       1.00      0.08      0.15        12\n",
      "     e: editor       1.00      0.08      0.15        12\n",
      "     i: editor       0.89      0.23      0.37       139\n",
      "i: institution       0.75      0.60      0.67        65\n",
      "b: institution       0.83      0.42      0.56        12\n",
      "e: institution       1.00      0.33      0.50        12\n",
      "    i: journal       0.71      0.37      0.48       166\n",
      "    b: journal       0.83      0.61      0.70        56\n",
      "    s: journal       0.00      0.00      0.00         1\n",
      "    e: journal       0.74      0.89      0.81        56\n",
      "   i: location       0.82      0.52      0.64        69\n",
      "   b: location       0.89      0.68      0.77        37\n",
      "   e: location       0.53      0.68      0.60        37\n",
      "       e: note       1.00      0.40      0.57         5\n",
      "       i: note       1.00      0.10      0.18        20\n",
      "       b: note       0.67      0.40      0.50         5\n",
      "      i: pages       0.97      0.95      0.96        61\n",
      "      b: pages       0.98      0.97      0.97        89\n",
      "      s: pages       0.00      0.00      0.00         1\n",
      "      e: pages       0.98      0.96      0.97        89\n",
      "  b: publisher       0.88      0.70      0.78        33\n",
      "  i: publisher       1.00      0.62      0.77        32\n",
      "  e: publisher       0.93      0.76      0.83        33\n",
      "       e: tech       0.88      0.58      0.70        12\n",
      "       b: tech       0.90      0.75      0.82        12\n",
      "       i: tech       0.81      0.45      0.58        29\n",
      "       s: tech       0.00      0.00      0.00         2\n",
      "      b: title       0.81      0.90      0.85       149\n",
      "      e: title       0.90      0.79      0.84       149\n",
      "      i: title       0.82      0.94      0.88       994\n",
      "     i: volume       0.80      0.92      0.86       107\n",
      "     e: volume       0.75      0.82      0.79        56\n",
      "     b: volume       0.96      0.88      0.92        56\n",
      "     s: volume       1.00      0.40      0.57         5\n",
      "\n",
      "   avg / total       0.83      0.83      0.82      4953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bib.test()\n",
    "print (\"Classifier Performance \\n Accuracy: {}\".format(bib.test_accuracy))\n",
    "print (tagtools.bieso_classification_report(bib.test_y, bib.test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Performance\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     b: author       0.99      0.97      0.98       148\n",
      "     i: author       0.99      0.97      0.98       970\n",
      "     e: author       0.98      0.97      0.97       148\n",
      "  e: booktitle       0.88      0.45      0.60        66\n",
      "  i: booktitle       0.99      0.47      0.63       477\n",
      "  b: booktitle       0.97      0.50      0.66        66\n",
      "       i: date       0.98      0.77      0.86       171\n",
      "       e: date       0.97      0.65      0.78       147\n",
      "       b: date       0.98      0.66      0.79       147\n",
      "     b: editor       0.00      0.00      0.00        12\n",
      "     e: editor       0.00      0.00      0.00        12\n",
      "     i: editor       0.00      0.00      0.00       139\n",
      "i: institution       1.00      0.17      0.29        65\n",
      "b: institution       1.00      0.25      0.40        12\n",
      "e: institution       1.00      0.25      0.40        12\n",
      "    i: journal       1.00      0.31      0.47       166\n",
      "    b: journal       0.93      0.45      0.60        56\n",
      "    s: journal       0.00      0.00      0.00         1\n",
      "    e: journal       0.93      0.45      0.60        56\n",
      "   i: location       1.00      0.29      0.45        69\n",
      "   b: location       0.92      0.30      0.45        37\n",
      "   e: location       1.00      0.32      0.49        37\n",
      "       e: note       0.00      0.00      0.00         5\n",
      "       i: note       1.00      0.05      0.10        20\n",
      "       b: note       0.02      0.40      0.05         5\n",
      "      i: pages       1.00      0.31      0.47        61\n",
      "      b: pages       1.00      0.47      0.64        89\n",
      "      s: pages       0.00      0.00      0.00         1\n",
      "      e: pages       1.00      0.47      0.64        89\n",
      "  b: publisher       1.00      0.24      0.39        33\n",
      "  i: publisher       1.00      0.19      0.32        32\n",
      "  e: publisher       1.00      0.24      0.39        33\n",
      "       e: tech       1.00      0.25      0.40        12\n",
      "       b: tech       1.00      0.25      0.40        12\n",
      "       i: tech       1.00      0.14      0.24        29\n",
      "       s: tech       0.00      0.00      0.00         2\n",
      "      b: title       1.00      0.60      0.75       149\n",
      "      e: title       0.98      0.59      0.74       149\n",
      "      i: title       1.00      0.60      0.75       994\n",
      "     i: volume       0.92      0.42      0.58       107\n",
      "     e: volume       0.93      0.46      0.62        56\n",
      "     b: volume       0.93      0.46      0.62        56\n",
      "     s: volume       1.00      0.20      0.33         5\n",
      "\n",
      "   avg / total       0.95      0.61      0.71      4953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Decoder Performance\")\n",
    "print(tagtools.bieso_classification_report(bib.test_y, bib.test_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipe Dev Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_classifier = sklearn.linear_model.SGDClassifier(loss=\"log\",\n",
    "                                           penalty=\"elasticnet\",\n",
    "                                           n_iter=5)\n",
    "\n",
    "\n",
    "rec_decoder = tagtools.BeamDecoder(initial_status,\n",
    "                                   is_consistent,\n",
    "                                   next_status,\n",
    "                                   do_special)\n",
    "\n",
    "rec = TaggingExperiment(recipe_data, \n",
    "                        recipe_features,\n",
    "                        rec_classifier,\n",
    "                        rec_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanya/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "rec.fit_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7989575577066269\n"
     ]
    }
   ],
   "source": [
    "print (rec.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed correctly.\n",
      "('1              ', u'\\tactual     s: qty    \\tpredicted  s: qty    ')\n",
      "('cup            ', u'\\tactual     s: unit   \\tpredicted  s: unit   ')\n",
      "('coarsely       ', u'\\tactual     b: comment\\tpredicted  b: comment')\n",
      "('chopped        ', u'\\tactual     e: comment\\tpredicted  e: comment')\n",
      "('leeks          ', u'\\tactual     s: name   \\tpredicted  s: name   ')\n"
     ]
    }
   ],
   "source": [
    "rec.visualize_classifier(20)\n",
    "rec.decode_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  e: comment       0.78      0.77      0.77      1063\n",
      "  b: comment       0.69      0.57      0.63      1063\n",
      "  s: comment       0.72      0.67      0.69       590\n",
      "  i: comment       0.72      0.85      0.78      2327\n",
      "    s: index       0.00      0.00      0.00         1\n",
      "     i: name       0.88      0.23      0.36       265\n",
      "     s: name       0.81      0.86      0.83      1118\n",
      "     e: name       0.82      0.77      0.79       915\n",
      "     b: name       0.74      0.82      0.78       915\n",
      "    b: other       0.85      0.19      0.31        57\n",
      "    s: other       0.69      0.39      0.50       443\n",
      "    e: other       0.92      0.19      0.32        57\n",
      "    i: other       0.50      0.20      0.29        45\n",
      "      b: qty       0.87      1.00      0.93       106\n",
      "      e: qty       0.72      0.99      0.84       106\n",
      "      s: qty       0.97      1.00      0.99      1555\n",
      "b: range_end       0.00      0.00      0.00         1\n",
      "s: range_end       0.91      0.76      0.83        38\n",
      "e: range_end       0.00      0.00      0.00         1\n",
      "     s: unit       0.89      0.99      0.94      1421\n",
      "\n",
      " avg / total       0.80      0.80      0.79     12087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (tagtools.bieso_classification_report(rec.dev_y, rec.dev_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  e: comment       0.76      0.01      0.02      1063\n",
      "  b: comment       0.11      0.14      0.12      1063\n",
      "  s: comment       0.69      0.04      0.08       590\n",
      "  i: comment       0.49      0.01      0.02      2327\n",
      "    s: index       0.00      0.00      0.00         1\n",
      "     i: name       0.94      0.06      0.11       265\n",
      "     s: name       0.88      0.03      0.06      1118\n",
      "     e: name       0.87      0.10      0.18       915\n",
      "     b: name       0.87      0.10      0.18       915\n",
      "    b: other       0.03      0.28      0.06        57\n",
      "    s: other       0.89      0.02      0.04       443\n",
      "    e: other       1.00      0.02      0.03        57\n",
      "    i: other       0.00      0.00      0.00        45\n",
      "      b: qty       0.91      0.99      0.95       106\n",
      "      e: qty       0.91      0.99      0.95       106\n",
      "      s: qty       0.00      0.00      0.00      1555\n",
      "b: range_end       0.00      0.00      0.00         1\n",
      "s: range_end       0.00      0.00      0.00        38\n",
      "e: range_end       0.00      0.00      0.00         1\n",
      "     s: unit       0.99      0.08      0.14      1421\n",
      "\n",
      " avg / total       0.61      0.06      0.09     12087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (tagtools.bieso_classification_report(rec.dev_y, rec.dev_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipe Test Data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Performance \n",
      " Accuracy: 0.809852388855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  e: comment       0.77      0.78      0.77      5185\n",
      "  b: comment       0.72      0.60      0.65      5185\n",
      "  s: comment       0.75      0.65      0.70      2912\n",
      "  i: comment       0.69      0.86      0.76      9295\n",
      "     i: name       0.82      0.19      0.30      1221\n",
      "     s: name       0.85      0.88      0.86      5935\n",
      "     e: name       0.84      0.81      0.82      4256\n",
      "     b: name       0.76      0.83      0.79      4256\n",
      "    b: other       0.88      0.14      0.24       270\n",
      "    s: other       0.72      0.40      0.51      2085\n",
      "    e: other       0.89      0.12      0.21       270\n",
      "    i: other       0.73      0.14      0.24       228\n",
      "      b: qty       0.93      1.00      0.96       560\n",
      "      e: qty       0.81      1.00      0.89       560\n",
      "      s: qty       0.98      1.00      0.99      7780\n",
      "b: range_end       0.00      0.00      0.00        11\n",
      "s: range_end       0.87      0.73      0.79       150\n",
      "e: range_end       0.00      0.00      0.00        11\n",
      "     s: unit       0.91      0.99      0.94      7075\n",
      "\n",
      " avg / total       0.81      0.81      0.80     57245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec.test()\n",
    "print (\"Classifier Performance \\n Accuracy: {}\".format(rec.test_accuracy))\n",
    "print (tagtools.bieso_classification_report(rec.test_y, rec.test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  e: comment       0.88      0.03      0.05      5185\n",
      "  b: comment       0.11      0.15      0.13      5185\n",
      "  s: comment       0.71      0.03      0.06      2912\n",
      "  i: comment       0.52      0.01      0.02      9295\n",
      "     i: name       0.94      0.07      0.13      1221\n",
      "     s: name       0.93      0.05      0.09      5935\n",
      "     e: name       0.87      0.10      0.19      4256\n",
      "     b: name       0.88      0.11      0.19      4256\n",
      "    b: other       0.03      0.26      0.05       270\n",
      "    s: other       0.71      0.02      0.03      2085\n",
      "    e: other       0.80      0.01      0.03       270\n",
      "    i: other       0.00      0.00      0.00       228\n",
      "      b: qty       0.96      0.99      0.98       560\n",
      "      e: qty       0.96      0.99      0.98       560\n",
      "      s: qty       1.00      0.00      0.00      7780\n",
      "b: range_end       0.00      0.00      0.00        11\n",
      "s: range_end       1.00      0.01      0.01       150\n",
      "e: range_end       0.00      0.00      0.00        11\n",
      "     s: unit       0.99      0.08      0.15      7075\n",
      "\n",
      " avg / total       0.77      0.07      0.10     57245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Decoder Performance\")\n",
    "print(tagtools.bieso_classification_report(rec.test_y, rec.test_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "First, multiple new features were added. These improved the precision of the classifier by around 3%--from 78% to 81%. Many of these features were tailored more toward the bibliography dataset (such as is_author and is_web_addr, among others), with the recipe dataset being more experimental. A feature that would have been beneficial to implement is is_booktitle, which could distinguish titles from booktitles (the classifier seemed to have some trouble with this). However, this seemed close to impossible logistically; there were few consistent differences between the two tags, and because it would need to be a list-level feature, it was difficult to find where exactly the \"booktitle\" and \"title\" tags began and ended in the list. Overall, however, the features implemented did demonstrate a 3% improvement in precision over approximately 10 trials.\n",
    "\n",
    "The development set precision for the bibliography data showed significant improvement after use of the decoder. Precision shot up from 80% to 97% after the four decoder functions were implemented. Accuracy did not improve to this extent, possibly due to multiple items being classified as the same specific feature but not necessarily the most correct one (adding more features would have increased the likelihood of this happening). This pattern was not observed with the recipe data, most likely because this was a more experimental part of this exercise and less features were implemented to detect features in recipe data.\n",
    "\n",
    "The test set precision for bibliography data also showed improvement (after use of the decoder from 83% to 95%. This pattern was observed consistently for approximately 10 trials. This pattern was not repeated for the recipe data, again most likely due to the prioritization of the bibliography data features. An improvement that could have been made for the recipe data trials is to implement more recipe-related features and separate the is_quantity and is_volume feature implementations between two separate feature processors. (These features appear very similar during processing of individual items.)\n",
    "\n",
    "Overall, the A* decoder with the improved `is_consistent`, `next_status`, and `do_special` functions greatly improved the precision of this classifier. On average, the dev set precisions improved by 16%, and the test set precisions improved by 15% on average. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
